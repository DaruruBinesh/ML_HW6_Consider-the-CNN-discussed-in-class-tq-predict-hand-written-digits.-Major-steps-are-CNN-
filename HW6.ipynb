{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EfbbhnvIbBM",
        "outputId": "2a42ac38-4ac7-41af-8861-3fb820385350"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 76s 125ms/step - loss: 0.7695 - accuracy: 0.9350 - val_loss: 0.0643 - val_accuracy: 0.9793\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 73s 122ms/step - loss: 0.0641 - accuracy: 0.9807 - val_loss: 0.0770 - val_accuracy: 0.9785\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 76s 126ms/step - loss: 0.0460 - accuracy: 0.9862 - val_loss: 0.0687 - val_accuracy: 0.9803\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 73s 121ms/step - loss: 0.0387 - accuracy: 0.9876 - val_loss: 0.0548 - val_accuracy: 0.9861\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 74s 124ms/step - loss: 0.0352 - accuracy: 0.9891 - val_loss: 0.0608 - val_accuracy: 0.9834\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 73s 122ms/step - loss: 0.0371 - accuracy: 0.9891 - val_loss: 0.0641 - val_accuracy: 0.9836\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 74s 124ms/step - loss: 0.0347 - accuracy: 0.9896 - val_loss: 0.0648 - val_accuracy: 0.9857\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 73s 122ms/step - loss: 0.0296 - accuracy: 0.9911 - val_loss: 0.0687 - val_accuracy: 0.9845\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 74s 124ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 0.0959 - val_accuracy: 0.9802\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 72s 120ms/step - loss: 0.0335 - accuracy: 0.9906 - val_loss: 0.0567 - val_accuracy: 0.9859\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "Expected (known values):  [3, 8, 6, 9, 0, 5, 6, 0, 7, 6]\n",
            "Predicted (from the CNN) : [3, 8, 6, 9, 0, 5, 6, 0, 7, 6]\n"
          ]
        }
      ],
      "source": [
        "# Q1 \n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "\n",
        "def sparseToOneHot(sparse):\n",
        "\tonehot = [0 for j in range(10)]\n",
        "\tonehot[sparse] = 1\n",
        "\treturn onehot\n",
        "\n",
        "\n",
        "def sparseLabelsToOneHot(sparseLabels):\n",
        "\treturn np.array([sparseToOneHot(sparseLabels[i]) for i in range(len(sparseLabels))])\n",
        "\n",
        "\n",
        "def grayscaleToRGB(image):\n",
        "\treturn np.repeat(image[:,:,np.newaxis], 3, axis=2)\n",
        "\n",
        "\n",
        "def grayscaleImagesToRGB(images):\n",
        "\treturn np.array([grayscaleToRGB(images[i]) for i in range(len(images))])\n",
        "\n",
        "\n",
        "def loadImagesAndLabels(filename):\n",
        "\tindex = pd.read_csv(filename)\n",
        "\timages = []\n",
        "\tfor file in index.loc[:,\"Filename\"]:\n",
        "\t\timages.append(np.resize(np.array(Image.open(file)), (32, 32, 3)))\n",
        "\treturn np.array(images), np.array(index.loc[:,\"Y0\":\"Y9\"])\n",
        "\n",
        "\n",
        "\n",
        "(training_images, training_labels), validation_data = tf.keras.datasets.mnist.load_data()\n",
        "training_images = grayscaleImagesToRGB(training_images)\n",
        "training_labels = sparseLabelsToOneHot(training_labels)\n",
        "validation_data = (grayscaleImagesToRGB(validation_data[0]), sparseLabelsToOneHot(validation_data[1]))\n",
        "\n",
        "prediction_images = training_images[30:40]\n",
        "prediction_labels = training_labels[30:40]\n",
        "training_images = training_images[40:]\n",
        "training_labels = training_labels[40:]\n",
        "\n",
        "\n",
        "\n",
        "input_shape = training_images[0].shape\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\ttf.keras.layers.Conv2D(filters=48, kernel_size=(5, 5), activation='relu'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Flatten(),\n",
        "\ttf.keras.layers.Dense(500, activation='relu'),\n",
        "\ttf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "\toptimizer='adam',\n",
        "\tloss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "\tmetrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "\tx=training_images,\n",
        "\ty=training_labels,\n",
        "\tvalidation_data=validation_data,\n",
        "\t\n",
        "\t\n",
        "\tepochs=10,\n",
        "\tbatch_size=100\n",
        ")\n",
        "\n",
        "\n",
        "def oneHotToIndex(arr):\n",
        "\treturn [np.argmax(x) for x in arr]\n",
        "\n",
        "predictions = model.predict(prediction_images)\n",
        "print(\"Expected (known values):  \" + str(oneHotToIndex(prediction_labels)))\n",
        "print(\"Predicted (from the CNN) : \" + str(oneHotToIndex(predictions)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2 \n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "def sparseToOneHot(sparse):\n",
        "\tonehot = [0 for j in range(10)]\n",
        "\tonehot[sparse] = 1\n",
        "\treturn onehot\n",
        "\n",
        "\n",
        "def sparseLabelsToOneHot(sparseLabels):\n",
        "\treturn np.array([sparseToOneHot(sparseLabels[i]) for i in range(len(sparseLabels))])\n",
        "\n",
        "\n",
        "def grayscaleToRGB(image):\n",
        "\treturn np.repeat(image[:,:,np.newaxis], 3, axis=2)\n",
        "\n",
        "\n",
        "def grayscaleImagesToRGB(images):\n",
        "\treturn np.array([grayscaleToRGB(images[i]) for i in range(len(images))])\n",
        "\n",
        "\n",
        "def loadImagesAndLabels(filename):\n",
        "\tindex = pd.read_csv(filename)\n",
        "\timages = []\n",
        "\tfor file in index.loc[:,\"Filename\"]:\n",
        "\t\timages.append(np.resize(np.array(Image.open(file)), (32, 32, 3)))\n",
        "\treturn np.array(images), np.array(index.loc[:,\"Y0\":\"Y9\"])\n",
        "\n",
        "\n",
        "\n",
        "(training_images, training_labels), validation_data = tf.keras.datasets.mnist.load_data()\n",
        "training_images = grayscaleImagesToRGB(training_images)\n",
        "training_labels = sparseLabelsToOneHot(training_labels)\n",
        "validation_data = (grayscaleImagesToRGB(validation_data[0]), sparseLabelsToOneHot(validation_data[1]))\n",
        "\n",
        "prediction_images = training_images[30:40]\n",
        "prediction_labels = training_labels[30:40]\n",
        "training_images = training_images[40:]\n",
        "training_labels = training_labels[40:]\n",
        "\n",
        "\n",
        "\n",
        "input_shape = training_images[0].shape\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Conv2D(filters=32, kernel_size=(6, 6), activation='relu'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(3, 3),padding='same'),\n",
        "\ttf.keras.layers.Conv2D(filters=48, kernel_size=(6, 6), activation='relu'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(3, 3),padding='same'),\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Flatten(),\n",
        "\ttf.keras.layers.Dense(500, activation='relu'),\n",
        "\ttf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "\toptimizer='adam',\n",
        "\tloss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "\tmetrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "\tx=training_images,\n",
        "\ty=training_labels,\n",
        "\tvalidation_data=validation_data,\n",
        "\t\n",
        "\t\n",
        "\tepochs=1,\n",
        "\tbatch_size=100\n",
        ")\n",
        "\n",
        "\n",
        "def oneHotToIndex(arr):\n",
        "\treturn [np.argmax(x) for x in arr]\n",
        "\n",
        "predictions = model.predict(prediction_images)\n",
        "print(\"Expected known values:  \" + str(oneHotToIndex(prediction_labels)))\n",
        "print(\"Prediction from the CNN: \" + str(oneHotToIndex(predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD6jWGW0L7uS",
        "outputId": "ecc0a5b3-d263-4063-8bae-53b681f79057"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600/600 [==============================] - 52s 85ms/step - loss: 0.5226 - accuracy: 0.9087 - val_loss: 0.0934 - val_accuracy: 0.9717\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "Expected known values:  [3, 8, 6, 9, 0, 5, 6, 0, 7, 6]\n",
            "Prediction from the CNN: [3, 8, 6, 9, 0, 5, 6, 0, 7, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3 \n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "\n",
        "def sparseToOneHot(sparse):\n",
        "\tonehot = [0 for j in range(10)]\n",
        "\tonehot[sparse] = 1\n",
        "\treturn onehot\n",
        "\n",
        "\n",
        "def sparseLabelsToOneHot(sparseLabels):\n",
        "\treturn np.array([sparseToOneHot(sparseLabels[i]) for i in range(len(sparseLabels))])\n",
        "\n",
        "\n",
        "def grayscaleToRGB(image):\n",
        "\treturn np.repeat(image[:,:,np.newaxis], 3, axis=2)\n",
        "\n",
        "\n",
        "def grayscaleImagesToRGB(images):\n",
        "\treturn np.array([grayscaleToRGB(images[i]) for i in range(len(images))])\n",
        "\n",
        "\n",
        "def loadImagesAndLabels(filename):\n",
        "\tindex = pd.read_csv(filename)\n",
        "\timages = []\n",
        "\tfor file in index.loc[:,\"Filename\"]:\n",
        "\t\timages.append(np.resize(np.array(Image.open(file)), (32, 32, 3)))\n",
        "\treturn np.array(images), np.array(index.loc[:,\"Y0\":\"Y9\"])\n",
        "\n",
        "\n",
        "\n",
        "(training_images, training_labels), validation_data = tf.keras.datasets.mnist.load_data()\n",
        "training_images = grayscaleImagesToRGB(training_images)\n",
        "training_labels = sparseLabelsToOneHot(training_labels)\n",
        "validation_data = (grayscaleImagesToRGB(validation_data[0]), sparseLabelsToOneHot(validation_data[1]))\n",
        "\n",
        "prediction_images = training_images[30:40]\n",
        "prediction_labels = training_labels[30:40]\n",
        "training_images = training_images[40:]\n",
        "training_labels = training_labels[40:]\n",
        "\n",
        "\n",
        "\n",
        "input_shape = training_images[0].shape\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Conv2D(filters=32, kernel_size=(6, 6), activation='tanh'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\ttf.keras.layers.Conv2D(filters=48, kernel_size=(6, 6), activation='tanh'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\t\n",
        "\ttf.keras.layers.Flatten(),\n",
        "\ttf.keras.layers.Dense(500, activation='tanh'),\n",
        "\ttf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "\toptimizer='adam',\n",
        "\tloss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "\tmetrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "\tx=training_images,\n",
        "\ty=training_labels,\n",
        "\tvalidation_data=validation_data,\n",
        "\t\n",
        "\t\n",
        "\tepochs=10,\n",
        "\tbatch_size=100\n",
        ")\n",
        "\n",
        "\n",
        "def oneHotToIndex(arr):\n",
        "\treturn [np.argmax(x) for x in arr]\n",
        "\n",
        "predictions = model.predict(prediction_images)\n",
        "print(\"Expected (known values):  \" + str(oneHotToIndex(prediction_labels)))\n",
        "print(\"Predicted (from the CNN): \" + str(oneHotToIndex(predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5KjCoZDMb1r",
        "outputId": "e1356c65-8e66-49b8-f3e9-e9cc8eead0db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 72s 120ms/step - loss: 0.1511 - accuracy: 0.9529 - val_loss: 0.0814 - val_accuracy: 0.9720\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 70s 116ms/step - loss: 0.0707 - accuracy: 0.9770 - val_loss: 0.0511 - val_accuracy: 0.9814\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 70s 116ms/step - loss: 0.0525 - accuracy: 0.9831 - val_loss: 0.0542 - val_accuracy: 0.9825\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 69s 115ms/step - loss: 0.0421 - accuracy: 0.9867 - val_loss: 0.0566 - val_accuracy: 0.9821\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 70s 117ms/step - loss: 0.0409 - accuracy: 0.9865 - val_loss: 0.0531 - val_accuracy: 0.9836\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 69s 116ms/step - loss: 0.0316 - accuracy: 0.9895 - val_loss: 0.0596 - val_accuracy: 0.9806\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 70s 117ms/step - loss: 0.0365 - accuracy: 0.9879 - val_loss: 0.0478 - val_accuracy: 0.9853\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 68s 114ms/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.0446 - val_accuracy: 0.9860\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 68s 113ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 0.0526 - val_accuracy: 0.9830\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 70s 116ms/step - loss: 0.0238 - accuracy: 0.9922 - val_loss: 0.0634 - val_accuracy: 0.9819\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "Expected (known values):  [3, 8, 6, 9, 0, 5, 6, 0, 7, 6]\n",
            "Predicted (from the CNN): [3, 8, 6, 9, 0, 5, 6, 0, 7, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4 \n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sparseToOneHot(sparse):\n",
        "\tonehot = [0 for j in range(10)]\n",
        "\tonehot[sparse] = 1\n",
        "\treturn onehot\n",
        "\n",
        "\n",
        "def sparseLabelsToOneHot(sparseLabels):\n",
        "\treturn np.array([sparseToOneHot(sparseLabels[i]) for i in range(len(sparseLabels))])\n",
        "\n",
        "\n",
        "def grayscaleToRGB(image):\n",
        "\treturn np.repeat(image[:,:,np.newaxis], 3, axis=2)\n",
        "\n",
        "\n",
        "def grayscaleImagesToRGB(images):\n",
        "\treturn np.array([grayscaleToRGB(images[i]) for i in range(len(images))])\n",
        "\n",
        "\n",
        "def loadImagesAndLabels(filename):\n",
        "\tindex = pd.read_csv(filename)\n",
        "\timages = []\n",
        "\tfor file in index.loc[:,\"Filename\"]:\n",
        "\t\timages.append(np.resize(np.array(Image.open(file)), (32, 32, 3)))\n",
        "\treturn np.array(images), np.array(index.loc[:,\"Y0\":\"Y9\"])\n",
        "\n",
        "\n",
        "\n",
        "(training_images, training_labels), validation_data = tf.keras.datasets.mnist.load_data()\n",
        "training_images = grayscaleImagesToRGB(training_images)\n",
        "training_labels = sparseLabelsToOneHot(training_labels)\n",
        "validation_data = (grayscaleImagesToRGB(validation_data[0]), sparseLabelsToOneHot(validation_data[1]))\n",
        "\n",
        "prediction_images = training_images[30:40]\n",
        "prediction_labels = training_labels[30:40]\n",
        "training_images = training_images[40:]\n",
        "training_labels = training_labels[40:]\n",
        "\n",
        "\n",
        "\n",
        "input_shape = training_images[0].shape\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Conv2D(filters=32, kernel_size=(6, 6), activation='tanh'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(3, 3),padding='same'),\n",
        "\ttf.keras.layers.Conv2D(filters=48, kernel_size=(6, 6), activation='tanh'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(3, 3),padding='same'),\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Flatten(),\n",
        "\ttf.keras.layers.Dense(500, activation='tanh'),\n",
        "\ttf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "\toptimizer='ftrl',\n",
        "\tloss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "\tmetrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "\tx=training_images,\n",
        "\ty=training_labels,\n",
        "\tvalidation_data=validation_data,\n",
        "\t\n",
        "\t\n",
        "\tepochs=1,\n",
        "\tbatch_size=100\n",
        ")\n",
        "\n",
        "\n",
        "def oneHotToIndex(arr):\n",
        "\treturn [np.argmax(x) for x in arr]\n",
        "\n",
        "predictions = model.predict(prediction_images)\n",
        "print(\"Expected (known values):  \" + str(oneHotToIndex(prediction_labels)))\n",
        "print(\"Predicted (from the CNN): \" + str(oneHotToIndex(predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDed1YvCPdum",
        "outputId": "bbc70b8b-0724-4881-d379-d005f3a04f9e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600/600 [==============================] - 50s 82ms/step - loss: 2.3025 - accuracy: 0.1116 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "Expected (known values):  [3, 8, 6, 9, 0, 5, 6, 0, 7, 6]\n",
            "Predicted (from the CNN): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Q5 \n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sparseToOneHot(sparse):\n",
        "\tonehot = [0 for j in range(10)]\n",
        "\tonehot[sparse] = 1\n",
        "\treturn onehot\n",
        "\n",
        "\n",
        "def sparseLabelsToOneHot(sparseLabels):\n",
        "\treturn np.array([sparseToOneHot(sparseLabels[i]) for i in range(len(sparseLabels))])\n",
        "\n",
        "\n",
        "def grayscaleToRGB(image):\n",
        "\treturn np.repeat(image[:,:,np.newaxis], 3, axis=2)\n",
        "\n",
        "\n",
        "def grayscaleImagesToRGB(images):\n",
        "\treturn np.array([grayscaleToRGB(images[i]) for i in range(len(images))])\n",
        "\n",
        "\n",
        "def loadImagesAndLabels(filename):\n",
        "\tindex = pd.read_csv(filename)\n",
        "\timages = []\n",
        "\tfor file in index.loc[:,\"Filename\"]:\n",
        "\t\timages.append(np.resize(np.array(Image.open(file)), (32, 32, 3)))\n",
        "\treturn np.array(images), np.array(index.loc[:,\"Y0\":\"Y9\"])\n",
        "\n",
        "\n",
        "\n",
        "(training_images, training_labels), validation_data = tf.keras.datasets.mnist.load_data()\n",
        "training_images = grayscaleImagesToRGB(training_images)\n",
        "training_labels = sparseLabelsToOneHot(training_labels)\n",
        "validation_data = (grayscaleImagesToRGB(validation_data[0]), sparseLabelsToOneHot(validation_data[1]))\n",
        "\n",
        "prediction_images = training_images[30:40]\n",
        "prediction_labels = training_labels[30:40]\n",
        "training_images = training_images[40:]\n",
        "training_labels = training_labels[40:]\n",
        "\n",
        "\n",
        "\n",
        "input_shape = training_images[0].shape\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5), activation='tanh'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        "\ttf.keras.layers.Conv2D(filters=48, kernel_size=(5, 5), activation='tanh'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(2, 2),padding='same'),\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Flatten(),\n",
        "\ttf.keras.layers.Dense(500, activation='tanh'),\n",
        "\ttf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "\toptimizer='ftrl',\n",
        "\tloss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "\tmetrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "\tx=training_images,\n",
        "\ty=training_labels,\n",
        "\tvalidation_data=validation_data,\n",
        "\t\n",
        "\t\n",
        "\tepochs=10,\n",
        "\tbatch_size=100\n",
        ")\n",
        "\n",
        "\n",
        "def oneHotToIndex(arr):\n",
        "\treturn [np.argmax(x) for x in arr]\n",
        "\n",
        "predictions = model.predict(prediction_images)\n",
        "print(\"Expected (known values):  \" + str(oneHotToIndex(prediction_labels)))\n",
        "print(\"Predicted (from the CNN): \" + str(oneHotToIndex(predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXC9ok0dP53m",
        "outputId": "2e99036c-c0c0-4279-c985-aeb09bcf144b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "600/600 [==============================] - 76s 126ms/step - loss: 2.3025 - accuracy: 0.1115 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 74s 123ms/step - loss: 2.3022 - accuracy: 0.1123 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 75s 125ms/step - loss: 2.3021 - accuracy: 0.1123 - val_loss: 2.3021 - val_accuracy: 0.1135\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 74s 124ms/step - loss: 2.3020 - accuracy: 0.1123 - val_loss: 2.3020 - val_accuracy: 0.1135\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 75s 126ms/step - loss: 2.3020 - accuracy: 0.1123 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 74s 123ms/step - loss: 2.3019 - accuracy: 0.1123 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 75s 126ms/step - loss: 2.3019 - accuracy: 0.1123 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 79s 132ms/step - loss: 2.3018 - accuracy: 0.1123 - val_loss: 2.3018 - val_accuracy: 0.1135\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 78s 130ms/step - loss: 2.3018 - accuracy: 0.1123 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 76s 127ms/step - loss: 2.3018 - accuracy: 0.1123 - val_loss: 2.3017 - val_accuracy: 0.1135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f735e971710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 102ms/step\n",
            "Expected (known values):  [3, 8, 6, 9, 0, 5, 6, 0, 7, 6]\n",
            "Predicted (from the CNN): [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def sparseToOneHot(sparse):\n",
        "\tonehot = [0 for j in range(10)]\n",
        "\tonehot[sparse] = 1\n",
        "\treturn onehot\n",
        "\n",
        "\n",
        "def sparseLabelsToOneHot(sparseLabels):\n",
        "\treturn np.array([sparseToOneHot(sparseLabels[i]) for i in range(len(sparseLabels))])\n",
        "\n",
        "\n",
        "def grayscaleToRGB(image):\n",
        "\treturn np.repeat(image[:,:,np.newaxis], 3, axis=2)\n",
        "\n",
        "\n",
        "def grayscaleImagesToRGB(images):\n",
        "\treturn np.array([grayscaleToRGB(images[i]) for i in range(len(images))])\n",
        "\n",
        "\n",
        "def loadImagesAndLabels(filename):\n",
        "\tindex = pd.read_csv(filename)\n",
        "\timages = []\n",
        "\tfor file in index.loc[:,\"Filename\"]:\n",
        "\t\timages.append(np.resize(np.array(Image.open(file)), (32, 32, 3)))\n",
        "\treturn np.array(images), np.array(index.loc[:,\"Y0\":\"Y9\"])\n",
        "\n",
        "\n",
        "\n",
        "(training_images, training_labels), validation_data = tf.keras.datasets.mnist.load_data()\n",
        "training_images = grayscaleImagesToRGB(training_images)\n",
        "training_labels = sparseLabelsToOneHot(training_labels)\n",
        "validation_data = (grayscaleImagesToRGB(validation_data[0]), sparseLabelsToOneHot(validation_data[1]))\n",
        "\n",
        "prediction_images = training_images[30:40]\n",
        "prediction_labels = training_labels[30:40]\n",
        "training_images = training_images[40:]\n",
        "training_labels = training_labels[40:]\n",
        "\n",
        "\n",
        "\n",
        "input_shape = training_images[0].shape\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.InputLayer(input_shape=input_shape),\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5), activation='relu'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(3, 3)),\n",
        "\ttf.keras.layers.Conv2D(filters=48, kernel_size=(5, 5), activation='relu'),\n",
        "\ttf.keras.layers.MaxPooling2D(pool_size=(3, 3)),\n",
        "\t\n",
        "\t\n",
        "\t\n",
        "\ttf.keras.layers.Flatten(),\n",
        "\ttf.keras.layers.Dense(500, activation='relu'),\n",
        "\ttf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(\n",
        "\toptimizer='ftrl',\n",
        "\tloss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "\tmetrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "\tx=training_images,\n",
        "\ty=training_labels,\n",
        "\tvalidation_data=validation_data,\n",
        "\t\n",
        "\t\n",
        "\tepochs=1,\n",
        "\tbatch_size=100\n",
        ")\n",
        "\n",
        "\n",
        "def oneHotToIndex(arr):\n",
        "\treturn [np.argmax(x) for x in arr]\n",
        "\n",
        "predictions = model.predict(prediction_images)\n",
        "print(\"Expected (known values):  \" + str(oneHotToIndex(prediction_labels)))\n",
        "print(\"Predicted (from the CNN): \" + str(oneHotToIndex(predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLPbFuF5TE04",
        "outputId": "90977f55-fecf-4fa9-f21b-6f7b8ae3710d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "600/600 [==============================] - 50s 83ms/step - loss: 0.5411 - accuracy: 0.8572 - val_loss: 0.1940 - val_accuracy: 0.9390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f72ee52bd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 81ms/step\n",
            "Expected (known values):  [3, 8, 6, 9, 0, 5, 6, 0, 7, 6]\n",
            "Predicted (from the CNN): [3, 8, 6, 7, 0, 5, 6, 0, 7, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b7bk73MBFJPz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}